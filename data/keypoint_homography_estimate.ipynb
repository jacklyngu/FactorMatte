{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74655d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import os\n",
    "from PIL import Image, ImageFilter \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "from scipy import ndimage\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_mask(mask, i):\n",
    "    \"\"\"\n",
    "    Because the edges of a segmentaation mask may be inacurate, we dilate it for \n",
    "    the subsequent feature matching. \n",
    "    The feature matcher will only look for correspondence points outside the mask.\n",
    "    \"\"\"\n",
    "    h, w = mask.shape\n",
    "    obj = np.nonzero(mask)\n",
    "    if len(obj[0]) == 0:\n",
    "        # occlusion\n",
    "        print('occlusion!')\n",
    "        return 255 - mask\n",
    "    mask_homo = np.ones_like(mask)*255\n",
    "    up, down = obj[0].min(), obj[0].max() \n",
    "    left, right = obj[1].min(), obj[1].max() \n",
    "    kernel = np.ones((50, 50), np.uint8)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    mask_homo -= mask\n",
    "    # You can adjust the edge erosion here to inlude more regions or less\n",
    "#     mask_homo[max(0, up-50): min(h, down+60), max(0, left-20): min(w, right+20)]=0\n",
    "    return mask_homo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4550b7cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the dataset folder\n",
    "dataset = \"composited/cloth/cloth_grail_5152\"\n",
    "img_f = sorted(os.listdir(os.path.join(\"../datasets/\", dataset, \"rgb\")))[0]\n",
    "print(img_f)\n",
    "img1 = cv2.imread(os.path.join(\"../datasets/\", dataset, \"rgb\", img_f))\n",
    "old_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "h, w, _ = img1.shape\n",
    "img1_acc_mask = 0\n",
    "for mask_ind in os.listdir(os.path.join(\"../datasets/\", dataset, \"mask\")):\n",
    "    print(mask_ind)\n",
    "    mask_f = sorted(os.listdir(os.path.join(\"../datasets/\", dataset, \"mask/\", mask_ind)))[0]\n",
    "    print(mask_f)\n",
    "    mask_i = cv2.imread(os.path.join(\"../datasets/\", dataset, \"mask/\", mask_ind, mask_f))\n",
    "    img1_acc_mask += mask_i\n",
    "img1_mask = feature_mask(cv2.cvtColor(img1_acc_mask, cv2.COLOR_BGR2GRAY),0)\n",
    "imshow(img1_mask)\n",
    "plt.show()\n",
    "sift = cv2.SIFT_create()\n",
    "# FLANN parameters\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)   # or pass empty dictionary\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "\n",
    "start_matrix = np.identity(3)\n",
    "with open(os.path.join(\"../datasets/\", dataset, 'homographies_raw.txt'), 'w') as f:\n",
    "    for i in range(len(os.listdir(os.path.join(\"../datasets/\", dataset, \"rgb\")))):\n",
    "        img_f = sorted(os.listdir(os.path.join(\"../datasets/\", dataset, \"rgb\")))[i]\n",
    "        frame = cv2.imread(os.path.join(\"../datasets/\", dataset, \"rgb\", img_f))\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "        frame_acc_mask = 0\n",
    "        # if there are multiple objects, collate their masks together, so that \n",
    "        # feature masking will consider the points within none of them.\n",
    "        # subfolders inside \"mask\" should be names as \"01\", \"02\", ...\n",
    "        for mask_ind in os.listdir(os.path.join(\"../datasets/\", dataset, \"mask\")):\n",
    "            mask_f = sorted(os.listdir(os.path.join(\"../datasets/\", dataset, \"mask/\", mask_ind)))[i]\n",
    "            mask_i = cv2.imread(os.path.join(\"../datasets/\", dataset, \"mask/\", mask_ind, mask_f))\n",
    "            frame_acc_mask += mask_i\n",
    "        frame_mask = feature_mask(cv2.cvtColor(frame_acc_mask, cv2.COLOR_BGR2GRAY), i)\n",
    "        imshow(frame_mask) \n",
    "        plt.show()\n",
    "        # find correspondence points between 2 frames by SIFT features.\n",
    "        kp1, des1 = sift.detectAndCompute(old_gray, img1_mask)\n",
    "        kp2, des2 = sift.detectAndCompute(frame_gray, frame_mask)\n",
    "        matches = flann.knnMatch(des1,des2,k=2)\n",
    "        tmp1 = cv2.drawKeypoints(old_gray, kp1, old_gray)\n",
    "        tmp2 = cv2.drawKeypoints(frame_gray, kp2, frame_gray)\n",
    "        plt.imshow(tmp1)\n",
    "        plt.show()\n",
    "        plt.imshow(tmp2)\n",
    "        plt.show()\n",
    "        good_points=[] \n",
    "        for m, n in matches: \n",
    "            good_points.append((m, m.distance/n.distance)) \n",
    "        # sort the correspondence points by confidence, by default we only use the best 50.\n",
    "        good_points.sort(key=lambda y: y[1])\n",
    "        query_pts = np.float32([kp1[m.queryIdx] \n",
    "                        .pt for m,d in good_points[:50]]).reshape(-1, 1, 2) \n",
    "\n",
    "        train_pts = np.float32([kp2[m.trainIdx] \n",
    "                        .pt for m,d in good_points[:50]]).reshape(-1, 1, 2) \n",
    "        print('len(query_pts)',len(query_pts))\n",
    "        # compute homography by the correspondence pairs\n",
    "        matrix, matrix_mask = cv2.findHomography(query_pts, train_pts, cv2.RANSAC, 5.0) \n",
    "        inliers = matrix_mask.sum()\n",
    "        print(i, inliers, matrix)\n",
    "        start_matrix = matrix @ start_matrix\n",
    "        f.write(' '.join([str(i) for i in start_matrix.flatten()])+'\\n')\n",
    "        imshow(frame_mask) \n",
    "        plt.show()\n",
    "        dst = cv2.warpPerspective(img1, start_matrix, (w, h), flags=cv2.INTER_LINEAR)\n",
    "        imshow(dst) \n",
    "        plt.show()\n",
    "        dst = cv2.warpPerspective(old_gray, matrix, (w, h), flags=cv2.INTER_LINEAR)\n",
    "        imshow(dst) \n",
    "        plt.show()\n",
    "        old_gray = frame_gray.copy()\n",
    "        img1_mask = frame_mask.copy()\n",
    "        imshow(frame_gray) \n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
